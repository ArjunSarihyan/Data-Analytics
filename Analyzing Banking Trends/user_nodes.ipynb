{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "177554c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7b6af32e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id_  area_id_  node_id_    act_date  deact_date  has_loan  is_act\n",
      "0       1         3         4  02-01-2020  03-01-2020         1       0\n",
      "1       2         3         5  03-01-2020  17-01-2020         0       1\n",
      "2       3         5         4  27-01-2020  18-02-2020         0       0\n",
      "3       4         5         4  07-01-2020  19-01-2020         1       1\n",
      "4       5         3         3  15-01-2020  23-01-2020         0       1\n",
      "...   ...       ...       ...         ...         ...       ...     ...\n",
      "3638  261         2         4  25-01-2020  07-02-2020         1       0\n",
      "3639  262         3         3  04-01-2020  13-01-2020         0       0\n",
      "3640  263         2         3  16-01-2020  16-01-2020         0       1\n",
      "3641  264         4         1  16-01-2020  31-01-2020         0       0\n",
      "3642  265         1         2  08-01-2020  28-01-2020         1       0\n",
      "\n",
      "[3643 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# Read the user_nodes.csv\n",
    "df = pd.read_csv('user_nodes.csv')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a41ff25d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   area_id_     id_\n",
      "0         1  193877\n",
      "1         2  182031\n",
      "2         3  204274\n",
      "3         4  164147\n",
      "4         5  162627\n"
     ]
    }
   ],
   "source": [
    "# Group by region_id and calculate the sum of consumer_ids for each unique region\n",
    "region_consumer_sum = df.groupby('area_id_')['id_'].sum().reset_index()\n",
    "\n",
    "# Display the result\n",
    "print(region_consumer_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "13187104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null Value Counts:\n",
      "id_           0\n",
      "area_id_      0\n",
      "node_id_      0\n",
      "act_date      0\n",
      "deact_date    0\n",
      "has_loan      0\n",
      "is_act        0\n",
      "dtype: int64\n",
      "\n",
      "DataFrame after removing rows with null values:\n",
      "      id_  area_id_  node_id_    act_date  deact_date  has_loan  is_act\n",
      "0       1         3         4  02-01-2020  03-01-2020         1       0\n",
      "1       2         3         5  03-01-2020  17-01-2020         0       1\n",
      "2       3         5         4  27-01-2020  18-02-2020         0       0\n",
      "3       4         5         4  07-01-2020  19-01-2020         1       1\n",
      "4       5         3         3  15-01-2020  23-01-2020         0       1\n",
      "...   ...       ...       ...         ...         ...       ...     ...\n",
      "3638  261         2         4  25-01-2020  07-02-2020         1       0\n",
      "3639  262         3         3  04-01-2020  13-01-2020         0       0\n",
      "3640  263         2         3  16-01-2020  16-01-2020         0       1\n",
      "3641  264         4         1  16-01-2020  31-01-2020         0       0\n",
      "3642  265         1         2  08-01-2020  28-01-2020         1       0\n",
      "\n",
      "[3643 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# Check for null values in the DataFrame\n",
    "null_counts = df.isnull().sum()\n",
    "print(\"Null Value Counts:\")\n",
    "print(null_counts)\n",
    "\n",
    "# Remove rows with null values\n",
    "df = df.dropna()\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "print(\"\\nDataFrame after removing rows with null values:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "35fcf2af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate Rows Count: 143\n",
      "\n",
      "DataFrame after removing duplicates:\n",
      "      id_  area_id_  node_id_    act_date  deact_date  has_loan  is_act\n",
      "0       1         3         4  02-01-2020  03-01-2020         1       0\n",
      "1       2         3         5  03-01-2020  17-01-2020         0       1\n",
      "2       3         5         4  27-01-2020  18-02-2020         0       0\n",
      "3       4         5         4  07-01-2020  19-01-2020         1       1\n",
      "4       5         3         3  15-01-2020  23-01-2020         0       1\n",
      "...   ...       ...       ...         ...         ...       ...     ...\n",
      "3495  496         3         4  25-02-2020  31-12-2021         0       0\n",
      "3496  497         5         4  27-05-2020  31-12-2021         0       1\n",
      "3497  498         1         2  05-04-2020  31-12-2021         0       0\n",
      "3498  499         5         1  03-02-2020  31-12-2021         1       1\n",
      "3499  500         2         2  15-04-2020  31-12-2021         0       1\n",
      "\n",
      "[3500 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicate rows in the DataFrame\n",
    "duplicate_count = df.duplicated().sum()\n",
    "print(\"Duplicate Rows Count:\", duplicate_count)\n",
    "\n",
    "# Remove duplicate rows\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "print(\"\\nDataFrame after removing duplicates:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6143ff75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned DataFrame:\n",
      "      consumer_id  region_id  node_id  start_date    end_date\n",
      "0               1          3        4  02-01-2020  03-01-2020\n",
      "1               2          3        5  03-01-2020  17-01-2020\n",
      "2               3          5        4  27-01-2020  18-02-2020\n",
      "3               4          5        4  07-01-2020  19-01-2020\n",
      "4               5          3        3  15-01-2020  23-01-2020\n",
      "...           ...        ...      ...         ...         ...\n",
      "3495          496          3        4  25-02-2020  31-12-2021\n",
      "3496          497          5        4  27-05-2020  31-12-2021\n",
      "3497          498          1        2  05-04-2020  31-12-2021\n",
      "3498          499          5        1  03-02-2020  31-12-2021\n",
      "3499          500          2        2  15-04-2020  31-12-2021\n",
      "\n",
      "[3500 rows x 5 columns]\n",
      "\n",
      "Data has been cleaned and saved to 'user_nodes_cleaned.csv'\n"
     ]
    }
   ],
   "source": [
    "# Data Cleaning \n",
    "# Step 1: Eliminate columns \"has_loan\" and \"is_act\"\n",
    "df = df.drop(columns=[\"has_loan\", \"is_act\"])\n",
    "\n",
    "# Step 2: Adjust column names\n",
    "df = df.rename(columns={\n",
    "    \"id_\": \"consumer_id\",\n",
    "    \"area_id_\": \"region_id\",\n",
    "    \"node_id_\": \"node_id\",\n",
    "    \"act_date\": \"start_date\",\n",
    "    \"deact_date\": \"end_date\"\n",
    "})\n",
    "\n",
    "# Step 3: Export the cleaned DataFrame to a CSV file without the index column\n",
    "df.to_csv(\"user_nodes_cleaned.csv\", index=False)\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "print(\"Cleaned DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "print(\"\\nData has been cleaned and saved to 'user_nodes_cleaned.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e8cda79a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   region_id  consumer_id\n",
      "0          1       187705\n",
      "1          2       174006\n",
      "2          3       199668\n",
      "3          4       156688\n",
      "4          5       158683\n"
     ]
    }
   ],
   "source": [
    "# Group by region_id and calculate the sum of consumer_ids for each unique region\n",
    "region_consumer_sum = df.groupby('region_id')['consumer_id'].sum().reset_index()\n",
    "\n",
    "# Display the result\n",
    "print(region_consumer_sum)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
